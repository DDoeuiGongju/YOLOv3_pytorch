{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_config(path: str):\n",
    "    print(path)\n",
    "    \"\"\"데이터셋 설정 파일 분석\"\"\"\n",
    "    options = {}\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        key, value = line.split('=')\n",
    "        options[key.strip()] = value.strip()\n",
    "    return options\n",
    "\n",
    "def load_classes(path: str):\n",
    "    print(path)\n",
    "    \"\"\"클래스 이름 로드\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        names = f.readlines()\n",
    "    for i, name in enumerate(names):\n",
    "        names[i] = name.strip()\n",
    "    return names\n",
    "\n",
    "def init_weights_normal(m):\n",
    "    \"\"\"정규분포 형태로 가중치 초기화\"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    # https://discuss.pytorch.org/t/object-has-no-attribute-weight/31526\n",
    "    # if classname.find(\"Conv\") != -1:\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data, 0.1)\n",
    "\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    y = x.new(x.shape)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n",
    "\n",
    "def ap_per_class(tp, conf, pred_cls, target_cls):\n",
    "    \"\"\"\n",
    "    Compute the average precision, given the Precision-Recall curve.\n",
    "    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n",
    "    # Arguments\n",
    "        tp:    True positives (list).\n",
    "        conf:  Objectness value from 0-1 (list).\n",
    "        pred_cls: Predicted object classes (list).\n",
    "        target_cls: True object classes (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by objectness\n",
    "    i = np.argsort(-conf)\n",
    "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
    "\n",
    "    # Find unique classes\n",
    "    unique_classes = np.unique(target_cls)\n",
    "\n",
    "    # Create Precision-Recall curve and compute AP for each class\n",
    "    ap, p, r = [], [], []\n",
    "    for c in tqdm.tqdm(unique_classes, desc=\"Compute AP\", leave=False):\n",
    "        i = pred_cls == c\n",
    "        n_gt = (target_cls == c).sum()  # Number of ground truth objects\n",
    "        n_p = i.sum()  # Number of predicted objects\n",
    "\n",
    "        if n_p == 0 and n_gt == 0:\n",
    "            continue\n",
    "        elif n_p == 0 or n_gt == 0:\n",
    "            ap.append(0)\n",
    "            r.append(0)\n",
    "            p.append(0)\n",
    "        else:\n",
    "            # Accumulate FPs and TPs\n",
    "            fpc = (1 - tp[i]).cumsum()\n",
    "            tpc = (tp[i]).cumsum()\n",
    "\n",
    "            # Recall\n",
    "            recall_curve = tpc / (n_gt + 1e-16)\n",
    "            r.append(recall_curve[-1])\n",
    "\n",
    "            # Precision\n",
    "            precision_curve = tpc / (tpc + fpc)\n",
    "            p.append(precision_curve[-1])\n",
    "\n",
    "            # AP from recall-precision curve\n",
    "            ap.append(compute_ap(recall_curve, precision_curve))\n",
    "\n",
    "    # Compute F1 score (harmonic mean of precision and recall)\n",
    "    p, r, ap = np.array(p), np.array(r), np.array(ap)\n",
    "    f1 = 2 * p * r / (p + r + 1e-16)\n",
    "\n",
    "    return p, r, ap, f1, unique_classes.astype(\"int32\")\n",
    "\n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\"\n",
    "    Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "\n",
    "def get_batch_statistics(outputs, targets, iou_threshold):\n",
    "    \"\"\"Compute true positives, predicted scores and predicted labels per batch.\"\"\"\n",
    "    batch_metrics = []\n",
    "    for i, output in enumerate(outputs):\n",
    "\n",
    "        if output is None:\n",
    "            continue\n",
    "\n",
    "        pred_boxes = output[:, :4]\n",
    "        pred_scores = output[:, 4]\n",
    "        pred_labels = output[:, -1]\n",
    "\n",
    "        true_positives = np.zeros(pred_boxes.shape[0])\n",
    "\n",
    "        annotations = targets[targets[:, 0] == i][:, 1:]\n",
    "        target_labels = annotations[:, 0] if len(annotations) else []\n",
    "        if len(annotations):\n",
    "            detected_boxes = []\n",
    "            target_boxes = annotations[:, 1:]\n",
    "\n",
    "            for pred_i, (pred_box, pred_label) in enumerate(zip(pred_boxes, pred_labels)):\n",
    "\n",
    "                # If targets are found break\n",
    "                if len(detected_boxes) == len(annotations):\n",
    "                    break\n",
    "\n",
    "                # Ignore if label is not one of the target labels\n",
    "                if pred_label not in target_labels:\n",
    "                    continue\n",
    "\n",
    "                iou, box_index = bbox_iou(pred_box.unsqueeze(0), target_boxes).max(0)\n",
    "                if iou >= iou_threshold and box_index not in detected_boxes:\n",
    "                    true_positives[pred_i] = 1\n",
    "                    detected_boxes += [box_index]\n",
    "        batch_metrics.append([true_positives, pred_scores, pred_labels])\n",
    "    return batch_metrics\n",
    "\n",
    "\n",
    "# 앵커 박스와 GT 박스 사이의 IOU 계산\n",
    "# 모양만 본다(위치 필요 x)\n",
    "def bbox_wh_iou(wh1, wh2):\n",
    "    wh2 = wh2.t()\n",
    "    w1, h1 = wh1[0], wh1[1]\n",
    "    w2, h2 = wh2[0], wh2[1]\n",
    "    inter_area = torch.min(w1, w2) * torch.min(h1, h2)\n",
    "    union_area = (w1 * h1 + 1e-16) + w2 * h2 - inter_area\n",
    "    return inter_area / union_area\n",
    "\n",
    "def build_targets(pred_boxes, pred_cls, target, anchors, ignore_thres, device):\n",
    "    # pred_boxes => (batch_size, anchor_num, gride, gride, 4)\n",
    "    # pred_cls   => (batch_size, anchor_num, gride, gride, 80)\n",
    "    nB = pred_boxes.size(0)   # batch 크기\n",
    "    nA = pred_boxes.size(1)   # anchor box 개수 = 3\n",
    "    nC = pred_cls.size(-1)    # class 개수 = 80\n",
    "    nG = pred_boxes.size(2)   # gird 크기 = 13 or 26 or 52\n",
    "    \n",
    "    # output 초기화\n",
    "    #(batch_size, anchor_num, gride, gride)\n",
    "    obj_mask = torch.zeros(nB, nA, nG, nG, dtype=torch.bool, device=device)    # 물체인지 아닌지\n",
    "    noobj_mask = torch.ones(nB, nA, nG, nG, dtype=torch.bool, device=device)\n",
    "    class_mask = torch.zeros(nB, nA, nG, nG, dtype=torch.float, device=device)   # 어느 클래스인지\n",
    "    iou_scores = torch.zeros(nB, nA, nG, nG, dtype=torch.float, device=device)\n",
    "    tx = torch.zeros(nB, nA, nG, nG, dtype=torch.float, device=device)   # target x_ctr\n",
    "    ty = torch.zeros(nB, nA, nG, nG, dtype=torch.float, device=device)   # target y_ctr\n",
    "    tw = torch.zeros(nB, nA, nG, nG, dtype=torch.float, device=device)   # target w\n",
    "    th = torch.zeros(nB, nA, nG, nG, dtype=torch.float, device=device)   # target h\n",
    "    # (batch_size, anchor_num, gride, gride, class_num)\n",
    "    tcls = torch.zeros(nB, nA, nG, nG, nC, dtype=torch.float, device=device)   # target class\n",
    "    \n",
    "    # 정규화된 4개의 변수를 실제 크기로 변환\n",
    "    # target shape: [index, class, x_ctr, y_ctr, w, h]\n",
    "    target_boxes = target[:, 2:6] * nG   # (batch_size, (x_ctr, y_ctr, w, h))\n",
    "    gxy = target_boxes[:, :2]   # (batch, (x_ctr, y_ctr))\n",
    "    gwh = target_boxes[:, 2:]   # (batch, (w, h))\n",
    "    \n",
    "    # print(gwh.shape)\n",
    "    \n",
    "    # 앵커 박스와 GT 박스 사이의 IOU 계산\n",
    "    # 두 박스는 wh는 다르지만 중심점의 좌표는 동일하므로 wh만 필요\n",
    "    # ious에는 총 3개의 anchor의 iou와 해당 anchor의 index가 들어있다. => (3, n)\n",
    "    ious = torch.stack([bbox_wh_iou(anchor, gwh) for anchor in anchors]) \n",
    "    _, best_ious_idx = ious.max(0)   # iou가 가장 큰 anchor의 index\n",
    "    \n",
    "    b, target_labels = target[:, :2].long().t()   # batch-size(타겟박스의 개수), (index, class)\n",
    "    gx, gy = gxy.t()\n",
    "    gw, gh = gwh.t()\n",
    "    gi, gj = gxy.long().t()   # 왼쪽 상단 모서리의 좌표\n",
    "    \n",
    "    # 마스크 설정 \n",
    "    obj_mask[b, best_ious_idx, gj, gi] = 1     # 대상이 있을 것으로 추정되는 cell을 1로\n",
    "    noobj_mask[b, best_ious_idx, gj, gi] = 0   # 대상이 있을 것으로 추정되는 cell을 0으로\n",
    "    \n",
    "    # IOU가 임계값 이상인 noobj 마스크를 0으로 설정(has-obj)\n",
    "    for i, anchor_ious in enumerate(ious.t()):\n",
    "        # ious.t() shape: [number of gt boxes, 3]\n",
    "        noobj_mask[b[i], anchor_ious > ignore_thres, gj[i], gi[i]] = 0\n",
    "        # b[i]: i번째 타겟박스\n",
    "        \n",
    "    # 타겟의 offset계산(cell에서의 위치 계산)\n",
    "    tx[b, best_ious_idx, gj, gi] = gx - gx.floor()   # .floor(): 소수점 아래 무시\n",
    "    ty[b, best_ious_idx, gj, gi] = gy - gy.floor()   # 결국 소수점 아래의 값만 남는다.\n",
    "    tw[b, best_ious_idx, gj, gi] = torch.log(gw / anchors[best_ious_idx][:, 0] + 1e-16)\n",
    "    th[b, best_ious_idx, gj, gi] = torch.log(gh / anchors[best_ious_idx][:, 1] + 1e-16)\n",
    "    \n",
    "    # target class label의 원핫인코딩 => 어떤 클래스인지\n",
    "    # [b, best_ious_idx, gj, gi, target_labels]: b번째 타겟이 best_ious_idx번쨰 엥커를 사용해 객체의 유형(target_labels)을 예측\n",
    "    tcls[b, best_ious_idx, gj, gi, target_labels] = 1\n",
    "    \n",
    "    # best Anchor에서의 label정확성 및 IOU 계산\n",
    "    # [b, best_n, gj, gi] index를 가져 와서 이것이 참 값과 같은지 판단하고 올바른 index얻음\n",
    "    class_mask[b, best_ious_idx, gj, gi] = (pred_cls[b, best_ious_idx, gj, gi].argmax(-1) == target_labels).float()\n",
    "    # IOU점수 계산. 클수록 점수가 높다.\n",
    "    iou_scores[b, best_ious_idx, gj, gi] = bbox_iou(pred_boxes[b, best_ious_idx, gj, gi], target_boxes, x1y1x2y2=False)\n",
    "    \n",
    "    # 타겟 신뢰도 계산\n",
    "    tconf = obj_mask.float()\n",
    "    \n",
    "    return iou_scores, class_mask, obj_mask, noobj_mask, tx, ty, tw, th, tcls, tconf\n",
    "\n",
    "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
    "    # xywh -> xyxy \n",
    "    if not x1y1x2y2:\n",
    "        # 중심과 너비에서 정확한 좌표(꼭지점 좌표)로 변환\n",
    "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "    else:\n",
    "        # bounding box의 좌표 가져오기\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "    # 교차 직사각형 좌표\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "    \n",
    "    # 교집합 넒이\n",
    "    # torch.calmp: min혹은 max의 범주에 해당하도록 값 변경\n",
    "    # 1을 더하는 이유: 0부터 시작하는 픽셀 좌표를 보완하기 위함이라는 말도 있고, 0으로 나눠지는것을 막기 위함이라는 말도 있는데 둘 중 뭔지 잘 모르겠다.\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(\n",
    "        inter_rect_y2 - inter_rect_y1 + 1, min=0\n",
    "    )\n",
    "    # 합집합 넓이\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "    union_area = b1_area + b2_area - inter_area\n",
    "    \n",
    "    # 0으로 나누는 것을 방지하는 작은 값\n",
    "    epsilon = 1e-16\n",
    "    \n",
    "    # iou계산\n",
    "    iou = inter_area / (union_area + epsilon)\n",
    "    \n",
    "    return iou\n",
    "    \n",
    "# test에서 사용\n",
    "# NMS: 예측한 박스들을 score가 높은 순으로 정렬 후 가장 높은 박스와 IoU가 일정 이상인 박스는 동일한 물체를 detect했다고 판단해 지운다\n",
    "# 10647개의 앵커에서 예측 결과를 계산한다.\n",
    "def non_max_suppression(prediction, conf_thres, nms_thres):\n",
    "    # From (center x(t_x), center y(t_y), width(t_w), height(t_h)) to (x1, y1, x2, y2)\n",
    "    prediction[..., :4] = xywh2xyxy(prediction[..., :4])\n",
    "    output = [None for _ in range(len(prediction))]\n",
    "    \n",
    "    for image_i, image_pred in enumerate(prediction):\n",
    "        # 임계값보다 작은 confidence score 필터링\n",
    "        # image_pred shape (10647,85)\n",
    "        image_pred = image_pred[image_pred[:, 4] >= conf_thres]\n",
    "        \n",
    "        # 모든 prediction이 필터링 되면 다음 이미지로,,\n",
    "        if not image_pred.size(0):\n",
    "            continue\n",
    "        \n",
    "        # 신뢰도에 분류예측의 최대값을 곱한 점수를 score로 정의한다.\n",
    "        # max(1): get max class (values, indices)\n",
    "        # [0]: get max class values\n",
    "        # category confidence = objectness x max_class_confidence \n",
    "        score = image_pred[:, 4] * image_pred[:, 5:].max(1)[0]\n",
    "        \n",
    "        # score가 높은 순으로 정렬한다.\n",
    "        # argsort는 내림차순 정렬이므로 -score를 한다.\n",
    "        image_pred = image_pred[(-score).argsort()]\n",
    "        # 모든 객체 호출, 분류 예측 값이 가장 높은 상자에 해당하는 행 선택!(keepdim -> 원핫 인코딩)\n",
    "        # 최대 클래스 신뢰도와 클래스 레이블을 얻는다.\n",
    "        class_confs, class_preds = image_pred[:, 5:].max(1, keepdim=True)\n",
    "        # 예측 상자와 score가 가장 높은 것 연결\n",
    "        detections = torch.cat((image_pred[:, :5], class_confs.float(), class_preds.float()), 1)\n",
    "        \n",
    "        # NMS 수행\n",
    "        keep_boxes = []\n",
    "        while detections.size(0):\n",
    "            # 첫 번쨰 상자와(score가장 높음) 모든 상자의 IOU를 계산하고 임계값보다 크면 1 아니면 0!\n",
    "            # return (0, 0, 1, 0 ...)\n",
    "            # unsqueeze(0): add dimension \n",
    "            large_overlap = bbox_iou(detections[0, :4].unsqueeze(0), detections[:, :4]) > nms_thres\n",
    "            # 첫 번쨰 상자와(score가장 높음) 동일한 범주의 레이블을 가진 모든 예측상자 매치\n",
    "            # return (0, 1, 0, 0 ...)\n",
    "            label_match = detections[0, -1] == detections[:, -1]\n",
    "            # iou가 임계값보다 크고, 동일한 범주의 label을 가지는 것들이 신뢰도를 가중치로 사용\n",
    "            invalid = large_overlap & label_match\n",
    "            weights = detections[invalid, 4:5]\n",
    "            \n",
    "            # 겹치는 상자의 좌표를 병합해 새로운 최적의 상자 좌표를 만든다.\n",
    "            detections[0, :4] = (weights * detections[invalid, :4]).sum(0) / weights.sum()\n",
    "            # 최적의 상자 유지\n",
    "            keep_boxes += [detections[0]]\n",
    "            # 이전 계산된 객체를 제외하고 다음 연산 수행\n",
    "            detections = detections[~invalid]\n",
    "        # 만일 keep_boxes가 None이 아닌 경우 스택의 모든 keep_box를 출력 목록에 저장\n",
    "        if keep_boxes:\n",
    "            output[image_i] = torch.stack(keep_boxes)\n",
    "\n",
    "    return output\n",
    "    # 출력의 형태: (batch_size, pred_boxes_num, 7)\n",
    "    # 7: x, y, w, h, conf, class_conf, class_pred\n",
    "    # pred_boxes_num: 각 사진에 pred_boxes_num 개의 상자가 있다는 것\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
